{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1.1: Setup and Introduction\n",
    "\n",
    "## Getting Started with GenAI and MLflow\n",
    "\n",
    "Welcome to the first notebook in our MLflow GenAI tutorial series! This notebook will guide you through setting up your environment and understanding the MLflow platform for GenAI development.\n",
    "\n",
    "### What You'll Learn\n",
    "- What MLflow is and why it's valuable for GenAI development\n",
    "- Core MLflow concepts and architecture\n",
    "- How to install and configure MLflow\n",
    "- How to start and access the MLflow UI\n",
    "\n",
    "### Prerequisites\n",
    "- Python 3.8 or higher\n",
    "- pip package manager\n",
    "- OpenAI API key (or other LLM provider credentials)\n",
    "- Basic understanding of Python and LLMs\n",
    "\n",
    "### Estimated Time: 15-20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: What is MLflow?\n",
    "\n",
    "**MLflow** is an open-source platform for managing the end-to-end machine learning lifecycle, with specialized support for GenAI and LLM applications.\n",
    "\n",
    "### Why MLflow for GenAI?\n",
    "\n",
    "1. **Open Source & Vendor-Neutral**: No lock-in to specific cloud providers or LLM vendors\n",
    "2. **OpenTelemetry Compatible**: Industry-standard observability that integrates with your existing stack\n",
    "3. **All-in-One Platform**: Unified solution for tracking, tracing, evaluation, and deployment\n",
    "4. **30+ Framework Integrations**: Works with OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more\n",
    "\n",
    "### Core Components for GenAI\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    MLflow Platform                      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                         â”‚\n",
    "â”‚  ğŸ“Š Experiment Tracking                                 â”‚\n",
    "â”‚     Track parameters, metrics, and artifacts            â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  ğŸ” Tracing (Observability)                             â”‚\n",
    "â”‚     Capture LLM calls, prompts, and tool usage          â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  ğŸ“ Prompt Management                                   â”‚\n",
    "â”‚     Version control for prompts and templates           â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  âœ… Evaluation                                          â”‚\n",
    "â”‚     LLM-as-judge metrics and custom scorers             â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  ğŸš€ Model Registry                                      â”‚\n",
    "â”‚     Versioning and deployment of models                 â”‚\n",
    "â”‚                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Your App   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ MLflow SDK   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Tracking     â”‚\n",
    "â”‚  (Python)    â”‚       â”‚              â”‚       â”‚ Server       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                      â”‚\n",
    "                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                        â”‚                           â”‚\n",
    "                                        â–¼                           â–¼\n",
    "                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                â”‚  Backend     â”‚          â”‚  Artifact    â”‚\n",
    "                                â”‚  Store       â”‚          â”‚  Store       â”‚\n",
    "                                â”‚ (metadata)   â”‚          â”‚ (files)      â”‚\n",
    "                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Installation\n",
    "\n",
    "Let's install MLflow and the required dependencies for working with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 3.9.0 not found\n"
     ]
    }
   ],
   "source": [
    "# Install MLflow and dependencies\n",
    "!pip install mlflow>=3.9.0 openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow version: 3.9.0rc0\n",
      "OpenAI version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "import mlflow\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "\n",
    "import openai\n",
    "print(f\"OpenAI version: {openai.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding MLflow Versions\n",
    "\n",
    "- **MLflow 3.x**: Latest release with enhanced tracing and evaluation (recommended)\n",
    "\n",
    "âœ… **You should see MLflow version 3.9.0 or higher**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Environment Configuration\n",
    "\n",
    "Configure your API keys and MLflow settings. We'll use a `.env` file for secure credential management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… .env file already exists.\n"
     ]
    }
   ],
   "source": [
    "# Create a .env file for your API keys (do this once)\n",
    "# This file should NOT be committed to version control\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "env_file = Path(\".env\")\n",
    "\n",
    "if not env_file.exists():\n",
    "    print(\"Creating .env file...\")\n",
    "    with open(env_file, \"w\") as f:\n",
    "        f.write(\"# MLflow GenAI Tutorial Configuration\\n\")\n",
    "        f.write(\"OPENAI_API_KEY=your-api-key-here\\n\")\n",
    "        f.write(\"\\n# MLflow Configuration\\n\")\n",
    "        f.write(\"MLFLOW_TRACKING_URI=http://localhost:5000\\n\")\n",
    "    print(\"âœ… Created .env file. Please edit it and add your OpenAI API key.\")\n",
    "else:\n",
    "    print(\"âœ… .env file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_databricks: True\n",
      "âœ… Using Databricks hosted foundational models\n",
      "âœ… Using Databricks workspace client and Databricks profile\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verify if using Databricks\n",
    "use_databricks = os.getenv(\"USE_DATABRICKS_CLIENT\") == \"True\"\n",
    "print(f\"use_databricks: {use_databricks}\")\n",
    "if use_databricks:\n",
    "    print(\"âœ… Using Databricks hosted foundational models\")\n",
    "    print(\"âœ… Using Databricks workspace client and Databricks profile\")\n",
    "else:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    # Verify API key is set (without displaying it)\n",
    "    if api_key and api_key != \"your-api-key-here\":\n",
    "        print(\"âœ… OpenAI API key is configured\")\n",
    "    else:\n",
    "        print(\"âŒ Please set your OPENAI_API_KEY in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”’ Security Best Practice\n",
    "\n",
    "**Always use environment variables or secure credential managers for API keys!**\n",
    "\n",
    "Never hardcode credentials in your notebooks or commit them to version control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: MLflow Tracking Setup\n",
    "\n",
    "MLflow stores experiment data in two places:\n",
    "1. **Backend Store**: Metadata (parameters, metrics, tags)\n",
    "2. **Artifact Store**: Files (models, plots, logs)\n",
    "\n",
    "For local development, we'll use the filesystem for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://localhost:5000\n",
      "\n",
      "Data will be stored in: /Users/jules/git-repos/mlflow-misc/tutorials/http:/localhost:5000\n"
     ]
    }
   ],
   "source": [
    "# Set tracking URI for sqlite backend\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"\\nData will be stored in: {Path(tracking_uri).absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/26 20:17:54 INFO mlflow.tracking.fluent: Experiment with name '00-setup-verification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created experiment: 00-setup-verification\n",
      "   Experiment ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a test experiment\n",
    "experiment_name = \"00-setup-verification\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"âœ… Created experiment: {experiment_name}\")\n",
    "print(f\"   Experiment ID: {mlflow.get_experiment_by_name(experiment_name).experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: First MLflow Run\n",
    "\n",
    "Let's create your first MLflow run to verify everything is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Run completed successfully!\n",
      "   Run ID: b0d2f3dfcebe4b5bb069af3d8faf91df\n",
      "   Experiment ID: 1\n",
      "ğŸƒ View run setup-test at: http://localhost:5000/#/experiments/1/runs/b0d2f3dfcebe4b5bb069af3d8faf91df\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Start a run\n",
    "with mlflow.start_run(run_name=\"setup-test\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"test_param\", \"hello-mlflow\")\n",
    "    mlflow.log_param(\"framework\", \"openai\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"setup_success\", 1.0)\n",
    "    mlflow.log_metric(\"timestamp\", time.time())\n",
    "    \n",
    "    # Log a text artifact\n",
    "    mlflow.log_text(\"MLflow GenAI Tutorial - Setup Complete!\", \"welcome.txt\")\n",
    "    \n",
    "    print(\"âœ… Run completed successfully!\")\n",
    "    print(f\"   Run ID: {run.info.run_id}\")\n",
    "    print(f\"   Experiment ID: {run.info.experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‰ Congratulations!\n",
    "\n",
    "You've successfully:\n",
    "- âœ… Installed MLflow\n",
    "- âœ… Configured your environment\n",
    "- âœ… Created an experiment\n",
    "- âœ… Logged your first run\n",
    "\n",
    "The data is now stored in the `mlruns` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Starting the MLflow UI\n",
    "\n",
    "The MLflow UI is a web-based interface for visualizing and comparing experiments.\n",
    "\n",
    "### To start the UI:\n",
    "\n",
    "**Option 1: From this notebook**\n",
    "```python\n",
    "# This will block the cell - run in a separate terminal instead\n",
    "!mlflow ui --port 5000\n",
    "```\n",
    "\n",
    "**Option 2: From terminal (recommended)**\n",
    "```bash\n",
    "cd /path/to/this/directory\n",
    "mlflow ui --port 5000\n",
    "```\n",
    "\n",
    "Then open your browser to: **http://localhost:5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display instructions for starting the UI\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘         MLflow UI - Getting Started                     â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "To start the MLflow UI, open a NEW terminal and run:\n",
    "\n",
    "    cd {}\n",
    "    mlflow ui --port 5000\n",
    "\n",
    "Then open your browser to:\n",
    "\n",
    "    http://localhost:5000\n",
    "\n",
    "You should see:\n",
    "  ğŸ“Š Your experiments listed on the left\n",
    "  ğŸ” Runs with parameters and metrics\n",
    "  ğŸ“ˆ Visualization capabilities\n",
    "\n",
    "Keep the terminal running while using the UI.\n",
    "Press Ctrl+C in the terminal to stop the UI server.\n",
    "\"\"\".format(Path.cwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Exploring the MLflow UI\n",
    "\n",
    "Once you have the UI running, explore these sections:\n",
    "\n",
    "### 1. Experiments View\n",
    "- Lists all your experiments\n",
    "- Shows experiment metadata and tags\n",
    "- Search and filter capabilities\n",
    "\n",
    "### 2. Runs View\n",
    "- Table of all runs in an experiment\n",
    "- Columns: parameters, metrics, tags, artifacts\n",
    "- Compare multiple runs\n",
    "- Search and filter runs\n",
    "\n",
    "### 3. Run Details\n",
    "- Complete information about a single run\n",
    "- Parameters, metrics, tags\n",
    "- Artifacts browser\n",
    "- Model information\n",
    "\n",
    "### 4. Traces Tab \n",
    "- Visualize LLM execution traces\n",
    "- Timeline view of spans\n",
    "- Input/output inspection\n",
    "- Performance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Verification Checklist\n",
    "\n",
    "Let's verify your setup is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using Databricks Workspace and Databricks profile\n",
      "âœ… Using Databricks hosted foundational models\n",
      "âœ… Using Databricks workspace client\n",
      "\n",
      "============================================================\n",
      "       SETUP VERIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "âœ… MLflow installed........................ 3.9.0rc0\n",
      "âœ… OpenAI SDK installed.................... 2.15.0\n",
      "âœ… Tracking URI set........................ http://localhost:5000\n",
      "âœ… Test experiment created................. 1\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ‰ Setup complete! You're ready to proceed to the next notebook.\n"
     ]
    }
   ],
   "source": [
    "# Verification script\n",
    "def verify_setup():\n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: MLflow installed\n",
    "    try:\n",
    "        import mlflow\n",
    "        checks.append((\"âœ…\", \"MLflow installed\", mlflow.__version__))\n",
    "    except ImportError:\n",
    "        checks.append((\"âŒ\", \"MLflow not installed\", \"N/A\"))\n",
    "    \n",
    "    # Check 2: OpenAI installed\n",
    "    try:\n",
    "        import openai\n",
    "        checks.append((\"âœ…\", \"OpenAI SDK installed\", openai.__version__))\n",
    "    except ImportError:\n",
    "        checks.append((\"âŒ\", \"OpenAI SDK not installed\", \"N/A\"))\n",
    "    \n",
    "    # Check 3: API key configured\n",
    "    use_databricks = os.getenv(\"USE_DATABRICKS_CLIENT\") == \"True\"\n",
    "    if use_databricks:\n",
    "        print(\"âœ… Using Databricks Workspace and Databricks profile\")\n",
    "        print(\"âœ… Using Databricks hosted foundational models\")\n",
    "        print(\"âœ… Using Databricks workspace client\")\n",
    "    else:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if api_key and api_key != \"your-api-key-here\":\n",
    "            checks.append((\"âœ…\", \"OpenAI API key configured\", \"***\"))\n",
    "        else:\n",
    "            checks.append((\"âŒ\", \"OpenAI API key not configured\", \"N/A\"))\n",
    "    \n",
    "    # Check 4: Tracking URI set\n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    checks.append((\"âœ…\", \"Tracking URI set\", tracking_uri))\n",
    "    \n",
    "    # Check 5: Test experiment exists\n",
    "    try:\n",
    "        exp = mlflow.get_experiment_by_name(\"00-setup-verification\")\n",
    "        if exp:\n",
    "            checks.append((\"âœ…\", \"Test experiment created\", exp.experiment_id))\n",
    "        else:\n",
    "            checks.append((\"âŒ\", \"Test experiment not found\", \"N/A\"))\n",
    "    except Exception as e:\n",
    "        checks.append((\"âŒ\", \"Test experiment not found\", str(e)))\n",
    "    \n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"       SETUP VERIFICATION RESULTS\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    for status, check, detail in checks:\n",
    "        print(f\"{status} {check:.<40} {detail}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Overall status\n",
    "    if all(status == \"âœ…\" for status, _, _ in checks):\n",
    "        print(\"\\nğŸ‰ Setup complete! You're ready to proceed to the next notebook.\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Some checks failed. Please review the errors above.\")\n",
    "\n",
    "verify_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Quick Reference - Common Commands\n",
    "\n",
    "Here are some common MLflow commands you'll use throughout the tutorials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘           MLflow Quick Reference Guide                       â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“Š EXPERIMENTS\n",
      "  mlflow.set_experiment(\"experiment-name\")\n",
      "  mlflow.get_experiment_by_name(\"experiment-name\")\n",
      "  mlflow.list_experiments()\n",
      "\n",
      "ğŸƒ RUNS\n",
      "  with mlflow.start_run(run_name=\"my-run\"):\n",
      "      # Your code here\n",
      "      pass\n",
      "\n",
      "ğŸ“ LOGGING\n",
      "  mlflow.log_param(\"key\", \"value\")              # Single value\n",
      "  mlflow.log_params({\"key1\": \"val1\", ...})      # Multiple values\n",
      "  mlflow.log_metric(\"accuracy\", 0.95)           # Single metric\n",
      "  mlflow.log_metrics({\"acc\": 0.95, ...})        # Multiple metrics\n",
      "  mlflow.log_text(text, \"file.txt\")             # Text artifact\n",
      "  mlflow.log_artifact(\"path/to/file\")           # File artifact\n",
      "\n",
      "ğŸ” TRACING (GenAI)\n",
      "  mlflow.openai.autolog()                       # Auto-trace OpenAI\n",
      "  mlflow.langchain.autolog()                    # Auto-trace LangChain\n",
      "  @mlflow.trace                                 # Manual tracing decorator\n",
      "\n",
      "ğŸ–¥ï¸  UI COMMANDS\n",
      "  mlflow ui                                     # Start UI (port 5000)\n",
      "  mlflow ui --port 8080                         # Custom port\n",
      "  mlflow ui --backend-store-uri                 # Custom backend\n",
      "  mlflow server --backend-store-uri sqlite:///mlflow.db --port 5000\n",
      "\n",
      "ğŸ”§ CONFIGURATION\n",
      "  mlflow.set_tracking_uri(\"uri\")                # Set tracking location\n",
      "  mlflow.get_tracking_uri()                     # Get current URI\n",
      "  mlflow.set_registry_uri(\"uri\")                # Set model registry\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick reference guide\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           MLflow Quick Reference Guide                       â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š EXPERIMENTS\n",
    "  mlflow.set_experiment(\"experiment-name\")\n",
    "  mlflow.get_experiment_by_name(\"experiment-name\")\n",
    "  mlflow.list_experiments()\n",
    "\n",
    "ğŸƒ RUNS\n",
    "  with mlflow.start_run(run_name=\"my-run\"):\n",
    "      # Your code here\n",
    "      pass\n",
    "\n",
    "ğŸ“ LOGGING\n",
    "  mlflow.log_param(\"key\", \"value\")              # Single value\n",
    "  mlflow.log_params({\"key1\": \"val1\", ...})      # Multiple values\n",
    "  mlflow.log_metric(\"accuracy\", 0.95)           # Single metric\n",
    "  mlflow.log_metrics({\"acc\": 0.95, ...})        # Multiple metrics\n",
    "  mlflow.log_text(text, \"file.txt\")             # Text artifact\n",
    "  mlflow.log_artifact(\"path/to/file\")           # File artifact\n",
    "\n",
    "ğŸ” TRACING (GenAI)\n",
    "  mlflow.openai.autolog()                       # Auto-trace OpenAI\n",
    "  mlflow.langchain.autolog()                    # Auto-trace LangChain\n",
    "  @mlflow.trace                                 # Manual tracing decorator\n",
    "\n",
    "ğŸ–¥ï¸  UI COMMANDS\n",
    "  mlflow ui                                     # Start UI (port 5000)\n",
    "  mlflow ui --port 8080                         # Custom port\n",
    "  mlflow ui --backend-store-uri                 # Custom backend\n",
    "  mlflow server --backend-store-uri sqlite:///mlflow.db --port 5000\n",
    "\n",
    "ğŸ”§ CONFIGURATION\n",
    "  mlflow.set_tracking_uri(\"uri\")                # Set tracking location\n",
    "  mlflow.get_tracking_uri()                     # Get current URI\n",
    "  mlflow.set_registry_uri(\"uri\")                # Set model registry\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, you:\n",
    "\n",
    "1. âœ… Learned what MLflow is and why it's valuable for GenAI\n",
    "2. âœ… Understood the MLflow architecture and core components\n",
    "3. âœ… Installed MLflow and required dependencies\n",
    "4. âœ… Configured your environment with API keys\n",
    "5. âœ… Set up MLflow tracking\n",
    "6. âœ… Created your first experiment and run\n",
    "7. âœ… Learned how to start the MLflow UI\n",
    "8. âœ… Verified your complete setup\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "You're now ready to move on to:\n",
    "\n",
    "**ğŸ““ Notebook 1.2: Experiment Tracking for LLMs**\n",
    "- Learn how to track LLM experiments\n",
    "- Log parameters, metrics, and artifacts\n",
    "- Compare different LLM configurations\n",
    "- Organize your GenAI experiments\n",
    "\n",
    "### Resources\n",
    "\n",
    "- ğŸ“š [MLflow Documentation](https://mlflow.org/docs/latest/)\n",
    "- ğŸ¯ [MLflow GenAI Guide](https://mlflow.org/docs/latest/genai/)\n",
    "- ğŸ’¬ [MLflow Community Slack](https://mlflow.org/community/)\n",
    "- ğŸ™ [MLflow GitHub](https://github.com/mlflow/mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**Problem: MLflow UI won't start**\n",
    "```bash\n",
    "# Solution: Check if port 5000 is already in use\n",
    "mlflow ui --port 5001\n",
    "```\n",
    "\n",
    "**Problem: OpenAI API key not recognized**\n",
    "```python\n",
    "# Solution: Restart the notebook kernel after adding to .env\n",
    "# Or manually set:\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n",
    "```\n",
    "\n",
    "**Problem: Module not found errors**\n",
    "```bash\n",
    "# Solution: Ensure you're using the correct Python environment\n",
    "pip install mlflow openai python-dotenv --upgrade\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
