{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1.8: Prompt Optimization with GEPA\n",
    "\n",
    "![](images/9_Prompt-Optimization-with-GEPA.png)\n",
    "\n",
    "## Automatically Improve Prompts Using MLflow's GEPA Integration\n",
    "\n",
    "In Tutorial 1.5, we manually iterated on prompts â€” writing better versions by hand and versioning them in the Prompt Registry. But what if an algorithm could do this automatically?\n",
    "\n",
    "This notebook demonstrates **GEPA (Genetic-Pareto)**, an automatic prompt optimization algorithm integrated into MLflow via `mlflow.genai.optimize_prompts()`.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- How GEPA automatically improves prompts\n",
    "- Using `mlflow.genai.optimize_prompts()` with the Prompt Registry\n",
    "- Evaluating prompt quality with `Correctness` scorer\n",
    "- Comparing original vs. optimized prompts\n",
    "\n",
    "### Prerequisites\n",
    "- Completed Notebook 1.5 (Prompt Management) and 1.7 (Evaluating Agents)\n",
    "- Understanding of the Prompt Registry and evaluation scorers\n",
    "\n",
    "### Estimated Time: 10-15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: How GEPA Works\n",
    "\n",
    "**GEPA (Genetic-Pareto)** optimizes prompts through an iterative cycle:\n",
    "\n",
    "```\n",
    "1. EVALUATE  â†’  Run the prompt on training examples, score with a judge\n",
    "2. REFLECT   â†’  Use an LLM to analyze failures and propose improvements\n",
    "3. MUTATE    â†’  Generate improved prompt variations\n",
    "4. SELECT    â†’  Keep the best-performing candidates (Pareto-optimal)\n",
    "5. REPEAT    â†’  Continue until budget exhausted or convergence\n",
    "```\n",
    "\n",
    "### Manual vs. Automatic Optimization\n",
    "\n",
    "| Approach | Method | Effort | Consistency |\n",
    "|----------|--------|--------|-------------|\n",
    "| **Manual** (Notebook 1.5) | Human writes better prompts | High | Variable |\n",
    "| **GEPA** (This notebook) | Algorithm evolves prompts | Low | Systematic |\n",
    "\n",
    "### Integration with Prompt Registry\n",
    "\n",
    "GEPA works directly with MLflow's Prompt Registry:\n",
    "- **Reads** your registered prompt as the starting point\n",
    "- **Optimizes** it through the evaluate-reflect-mutate cycle\n",
    "- **Registers** the improved version automatically as a new version\n",
    "\n",
    "> **Note:** GEPA requires the `gepa` package. Install it with: `pip install gepa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:38:46 INFO mlflow.tracking.fluent: Experiment with name '09-prompt-optimization' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment configured\n",
      "   Provider: OpenAI\n",
      "   Model: gpt-5.2\n",
      "   Optimizer model: openai:/gpt-5.2\n",
      "   Tracking URI: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "from utils.clnt_utils import is_databricks_ai_gateway_client, get_databricks_ai_gateway_client, get_openai_client, get_ai_gateway_model_names\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"09-prompt-optimization\")\n",
    "\n",
    "# Configure client and model based on provider\n",
    "use_databricks_provider = is_databricks_ai_gateway_client()\n",
    "if use_databricks_provider:\n",
    "    client = get_databricks_ai_gateway_client()\n",
    "    model_name = get_ai_gateway_model_names()[0]\n",
    "    optimizer_model = f\"databricks:/{model_name}\"\n",
    "else:\n",
    "    client = get_openai_client()\n",
    "    model_name = \"gpt-5.2\"\n",
    "    optimizer_model = f\"openai:/{model_name}\"\n",
    "\n",
    "# Enable autologging\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "print(\"\\u2705 Environment configured\")\n",
    "print(f\"   Provider: {'Databricks AI Gateway' if use_databricks_provider else 'OpenAI'}\")\n",
    "print(f\"   Model: {model_name}\")\n",
    "print(f\"   Optimizer model: {optimizer_model}\")\n",
    "print(f\"   Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Register a Baseline Prompt\n",
    "\n",
    "We'll use the same basic Q&A prompt from Notebook 1.5's Prompt Library (`qa_simple`). We register it fresh here so this notebook is self-contained.\n",
    "\n",
    "This minimal prompt is an ideal optimization target â€” it has maximum room for GEPA to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:38:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: gepa-qa-simple, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Baseline prompt registered\n",
      "   Name: gepa-qa-simple\n",
      "   Version: 1\n",
      "   URI: prompts:/gepa-qa-simple/1\n",
      "   Template: 'Answer this question: {{ question }}'\n"
     ]
    }
   ],
   "source": [
    "# Register the baseline prompt (same template as qa_simple from Notebook 1.5)\n",
    "baseline_prompt = mlflow.genai.register_prompt(\n",
    "    name=\"gepa-qa-simple\",\n",
    "    template=\"Answer this question: {{ question }}\",\n",
    "    commit_message=\"Baseline prompt for GEPA optimization\",\n",
    "    tags={\"author\": \"jules\", \"use_case\": \"Simple Q&A\", \"status\": \"baseline\"}\n",
    ")\n",
    "\n",
    "print(\"\\u2705 Baseline prompt registered\")\n",
    "print(f\"   Name: {baseline_prompt.name}\")\n",
    "print(f\"   Version: {baseline_prompt.version}\")\n",
    "print(f\"   URI: {baseline_prompt.uri}\")\n",
    "print(f\"   Template: '{baseline_prompt.template}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Prepare Training Data and Predict Function\n",
    "\n",
    "GEPA needs two things:\n",
    "1. **Training data** â€” example input/output pairs so it can evaluate prompt quality\n",
    "2. **Predict function** â€” a callable that loads the prompt, fills it, and calls the LLM\n",
    "\n",
    "### Why Training Data Design Matters\n",
    "\n",
    "GEPA improves prompts by finding gaps between actual outputs and expected responses.\n",
    "If the baseline prompt already produces near-perfect answers (common with powerful LLMs),\n",
    "GEPA has **no signal to improve** and will register the original template unchanged.\n",
    "\n",
    "To give GEPA room to work, our training examples require **specific structure and detail**\n",
    "that the bare-bones prompt `\"Answer this question: ...\"` won't naturally produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training data prepared: 6 examples\n",
      "   (Questions require specific structure/format the baseline prompt can't guide)\n",
      "âœ… Predict function defined\n",
      "   Loads prompt from: prompts:/gepa-qa-simple/1\n"
     ]
    }
   ],
   "source": [
    "from mlflow.genai import optimize_prompts\n",
    "from mlflow.genai.optimize.optimizers import GepaPromptOptimizer\n",
    "from mlflow.genai.scorers import Correctness\n",
    "\n",
    "# Training data: questions that require STRUCTURED, DETAILED responses.\n",
    "# The bare-bones baseline prompt won't guide the LLM to produce these formats,\n",
    "# giving GEPA a clear signal to add structure/instructions to the prompt.\n",
    "train_data = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Explain MLflow Tracking to a beginner in exactly 3 sentences.\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"MLflow Tracking is a component that automatically logs your machine learning experiments. \"\n",
    "                \"It records parameters, metrics, and model artifacts so you can compare different runs side by side. \"\n",
    "                \"You can view all your experiments through the MLflow UI dashboard.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"List the top 3 benefits of using vector embeddings. Number each benefit.\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"1. Semantic similarity â€” embeddings capture meaning, so related concepts like 'happy' and 'joyful' are close in vector space.\\n\"\n",
    "                \"2. Efficiency â€” they compress high-dimensional sparse data into compact dense vectors, making computation faster.\\n\"\n",
    "                \"3. Transfer learning â€” pre-trained embeddings can be fine-tuned for specific downstream tasks without training from scratch.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Compare RAG and fine-tuning in exactly 2 sentences.\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"RAG retrieves relevant documents at inference time to augment the LLM's context, \"\n",
    "                \"while fine-tuning modifies the model's weights on domain-specific training data. \"\n",
    "                \"RAG allows dynamic knowledge updates without retraining, while fine-tuning creates a \"\n",
    "                \"specialized model that may lose some general capabilities.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is prompt engineering? Answer with a definition followed by 2 best practices.\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"Prompt engineering is the practice of designing and refining instructions given to LLMs \"\n",
    "                \"to produce desired outputs reliably.\\n\\n\"\n",
    "                \"Best practices:\\n\"\n",
    "                \"1. Be specific and explicit â€” clearly state the format, length, and style you expect.\\n\"\n",
    "                \"2. Provide examples â€” include one or two input/output examples to guide the model's behavior.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Describe the MLflow Model Registry in one paragraph of 3-4 sentences.\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"The MLflow Model Registry is a centralized store for managing the full lifecycle of ML models. \"\n",
    "                \"It provides model versioning, so you can track how models evolve over time. \"\n",
    "                \"Teams can transition models through stages like Staging and Production using aliases. \"\n",
    "                \"It also supports annotations and approval workflows for collaborative model governance.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is a vector database? Structure your answer as: Definition, then Use Cases (2 bullet points).\"},\n",
    "        \"expectations\": {\n",
    "            \"expected_response\": (\n",
    "                \"A vector database is a specialized database designed to store, index, and efficiently query \"\n",
    "                \"high-dimensional vector embeddings.\\n\\n\"\n",
    "                \"Use cases:\\n\"\n",
    "                \"â€¢ Semantic search â€” finding documents or products by meaning rather than keyword matching.\\n\"\n",
    "                \"â€¢ RAG pipelines â€” retrieving relevant context for LLM generation to improve answer accuracy.\"\n",
    "            )\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Predict function: GEPA calls this repeatedly during optimization.\n",
    "# During optimization, GEPA patches PromptVersion.template so that\n",
    "# load_prompt() returns the MUTATED template instead of the original.\n",
    "def predict_qa(question: str) -> str:\n",
    "    \"\"\"Load the prompt from the registry, fill it, and call the LLM.\"\"\"\n",
    "    prompt = mlflow.genai.load_prompt(baseline_prompt.uri)\n",
    "    filled = prompt.format(question=question)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": filled}],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(f\"\\u2705 Training data prepared: {len(train_data)} examples\")\n",
    "print(\"   (Questions require specific structure/format the baseline prompt can't guide)\")\n",
    "print(\"\\u2705 Predict function defined\")\n",
    "print(f\"   Loads prompt from: {baseline_prompt.uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Run GEPA Optimization\n",
    "\n",
    "Now we run the optimization. GEPA will:\n",
    "1. Evaluate the baseline prompt using the `Correctness` scorer\n",
    "2. Reflect on failures and generate improved variations\n",
    "3. Select the best candidates and repeat\n",
    "4. Register the optimized prompt as a new version in the Prompt Registry\n",
    "\n",
    "> **Note:** This may take 3-5 minutes. The training examples require structured responses\n",
    "> that the bare-bones prompt can't produce well, giving GEPA a clear optimization signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:39:09 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "2026/02/09 14:39:09 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset. To disable this check, set the MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION environment variable to True.\n",
      "/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Base program full valset score: 0.3333333333333333 over 6 / 6 examples\n",
      "Iteration 1: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 1: Proposed new text for gepa-qa-simple: Answer the userâ€™s question directly and follow any formatting constraints in the question (e.g., â€œ3â€“4 sentences,â€ â€œnumber each benefit,â€ â€œDefinition then 2 bullet pointsâ€).\n",
      "\n",
      "Important: Only state information that is explicitly supported by the provided/reference material for this task. Do NOT add plausible-sounding extras or unstated features. Avoid introducing domain-specific terms unless the source text mentions them (e.g., donâ€™t claim MLflow Model Registry uses â€œaliasesâ€ for stage transitions or that it supports â€œannotationsâ€ unless that is explicitly stated; donâ€™t mention â€œtransfer learning,â€ â€œpre-trained embeddings,â€ â€œfine-tuning,â€ or â€œcompression of sparse vectors into dense vectorsâ€ unless explicitly supported).\n",
      "\n",
      "When describing concepts, prefer safe, broadly supported statements such as:\n",
      "- MLflow Model Registry: centralized store/repository for managing the ML model lifecycle; model versioning; tracking versions/lineage/metadata; stage-based workflows like Staging/Production/Archived; controlled promotion/approvals/auditability only if stated.\n",
      "- Vector embeddings: capture semantic meaning; enable semantic matching beyond keywords; support similarity search/clustering/deduplication/recommendations if stated.\n",
      "- Vector database: stores/indexes/queries high-dimensional vector embeddings; retrieves similar items via similarity/nearest-neighbor search; common use cases include semantic search and RAG (retrieval-augmented generation) if stated.\n",
      "\n",
      "Be concise, accurate, and do not hedge with speculation. If the question asks for a specific structure, mirror it exactly.\n",
      "Iteration 1: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 2: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 2: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using only information that is explicitly stated or directly supported by the provided source document/context for this task (if any). Do not add extra claims, implications, or â€œcommon knowledgeâ€ details that are not supported (e.g., donâ€™t claim fine-tuning reduces general capability unless the source says so; donâ€™t claim MLflow Tracking â€œautomaticallyâ€ logs unless the source says it is automatic).\n",
      "\n",
      "Requirements:\n",
      "- Follow the userâ€™s formatting constraints exactly (e.g., â€œexactly 2 sentencesâ€, â€œexactly 3 sentencesâ€, â€œdefinition followed by 2 best practicesâ€).\n",
      "- If a constraint is given, obey it precisely (sentence count, list count, order).\n",
      "- Keep wording tight and factual; prefer paraphrasing the supported points rather than embellishing.\n",
      "- If the question asks for comparisons/definitions/explanations, include only the key supported distinctions/features:\n",
      "  - RAG: base model unchanged; retrieves relevant external documents at query/inference time to augment context; easier to update knowledge without retraining; can help with citing sources only if supported by the source.\n",
      "  - Fine-tuning: updates model weights using training data to change behavior/embed domain knowledge; harder to refresh; may be more expensive; traceable citations are not guaranteedâ€”only mention these if the source states them.\n",
      "  - MLflow Tracking: records/organizes experiments; logs parameters, metrics, and artifacts; supports comparing runs; accessible via UI and/or APIâ€”do not state â€œautomatic loggingâ€ unless the source explicitly says so.\n",
      "- If the user requests a structure (e.g., â€œdefinition + 2 best practicesâ€), output that structure and nothing extra.\n",
      "\n",
      "If the needed detail is not supported by the source/context, omit it rather than guessing.\n",
      "Iteration 2: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 3: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 3: Proposed new text for gepa-qa-simple: Answer the userâ€™s question directly and follow any formatting constraints in the question (e.g., exact sentence count, required headings, number of bullet points, paragraph length).\n",
      "\n",
      "When the question is about these ML/LLM topics, ensure you include the following domain facts:\n",
      "\n",
      "- Vector database: a specialized database to store and index high-dimensional vector embeddings (numeric representations of data such as text/images/audio) and efficiently retrieve similar items via similarity / nearest-neighbor search. Common use cases include semantic search (meaning-based retrieval) and RAG pipelines (retrieving relevant context for LLM generation).\n",
      "- MLflow Tracking: a tool/component for recording and organizing ML experiments; it logs parameters, metrics (e.g., accuracy/loss), and artifacts (models/plots/files), enabling comparison and reproducibility; runs can be viewed/searched via the MLflow UI and/or API.\n",
      "- MLflow Model Registry: a centralized store/repository for managing the full lifecycle of ML models; supports model versioning, metadata/lineage, registering models from runs, stage-based workflows (e.g., Staging, Production, Archived), and collaboration features like annotations and approvals/approval workflows. Do NOT claim that aliases are used for stage transitions unless the question explicitly provides that fact.\n",
      "\n",
      "Do not add extra unsupported product-specific details; prefer wording that is supported by the above facts. Keep the answer concise unless the question requests more detail.\n",
      "Iteration 3: New subsample score 0.0 is not better than old score 2.0, skipping\n",
      "Iteration 4: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 4: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly stated in the provided source/document for that question.\n",
      "\n",
      "Requirements:\n",
      "- Do not add extra facts, implications, or common â€œbackground knowledgeâ€ that are not directly supported by the source (e.g., donâ€™t mention efficiency via sparseâ†’dense speedups, pre-trained/fine-tuning transfer learning, or â€œfine-tuning may lose general capabilitiesâ€ unless the source explicitly says so).\n",
      "- If the question asks for a specific format or constraints (e.g., â€œexactly 2 sentencesâ€, â€œnumber each benefitâ€, â€œdefinition + 2 best practicesâ€), follow them exactly.\n",
      "- Keep phrasing grounded in the source; you may paraphrase but must preserve the sourceâ€™s meaning.\n",
      "- If the source does not contain enough information to fully answer, respond with what is supported and explicitly note what cannot be answered from the source.\n",
      "\n",
      "Now answer:\n",
      "{{ question }}\n",
      "Iteration 4: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 5: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 5: Proposed new text for gepa-qa-simple: You are a QA assistant. Answer the userâ€™s question directly and ONLY with information that is explicitly stated in the provided reference/document/context (if any). Do not add extra claims, examples, mechanisms, or benefits unless they are supported verbatim or unambiguously by the reference.\n",
      "\n",
      "Instructions:\n",
      "- Follow the userâ€™s requested format exactly (e.g., numbered list, â€œDefinitionâ€ then â€œUse Cases (2 bullet points)â€, â€œdefinition followed by 2 best practicesâ€, etc.).\n",
      "- Keep answers concise and focused on what was asked.\n",
      "- If the user requests a specific number of items (e.g., â€œtop 3â€, â€œ2 bullet pointsâ€), provide exactly that many.\n",
      "- Do not introduce niche additions like â€œtransfer learning,â€ â€œfine-tuning,â€ or â€œcompressing high-dimensional sparse data into dense vectorsâ€ unless the reference explicitly mentions them.\n",
      "- Use safe, widely supported phrasing when the reference is general (e.g., embeddings â€œcapture meaningâ€ and enable â€œsemantic search/retrievalâ€; vector databases â€œstore/index vector embeddingsâ€ and support â€œefficient similarity/nearest-neighbor searchâ€; prompt engineering is â€œdesigning/refining prompts to reliably get desired outputs,â€ with best practices like â€œbe specific/structuredâ€ and â€œiterate/provide examplesâ€ only if supported).\n",
      "- If there is not enough information in the reference to answer a part of the question, say so briefly (e.g., â€œNot specified in the provided material.â€) rather than guessing.\n",
      "\n",
      "Task template:\n",
      "Answer this question: {{ question }}\n",
      "Iteration 5: New subsample score 0.0 is not better than old score 2.0, skipping\n",
      "Iteration 6: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 6: Proposed new text for gepa-qa-simple: Answer the userâ€™s question clearly and directly, following any formatting constraints exactly (e.g., â€œexactly 2 sentencesâ€, â€œexactly 3 sentencesâ€, â€œone paragraph of 3â€“4 sentencesâ€).\n",
      "\n",
      "Ground your response strictly in the provided reference/document context for the task (do not add extra features, mechanisms, or implications that are not explicitly stated or unambiguously implied). In particular, avoid â€œnice-to-haveâ€ additions such as:\n",
      "- claims about capability tradeoffs (e.g., â€œfine-tuning may lose general capabilitiesâ€) unless the source explicitly says so,\n",
      "- MLflow Model Registry â€œaliasesâ€ or â€œannotationsâ€ unless explicitly mentioned,\n",
      "- â€œautomaticâ€ logging for MLflow Tracking unless the source explicitly states it is automatic.\n",
      "\n",
      "When comparing concepts, stick to these supported points (only if consistent with the provided source):\n",
      "- RAG: retrieves relevant external documents at query/inference time to augment context/condition responses; keeps knowledge up to date without changing model weights.\n",
      "- Fine-tuning: updates model weights using training data to bake in behaviors/knowledge; can improve style/task performance; is harder to update than RAG; may still hallucinate without external grounding.\n",
      "- MLflow Model Registry: centralized repository/store for managing the ML model lifecycle; supports registering models from runs, versioning, metadata/lineage, artifacts/evaluation details; stage-based workflows (e.g., Staging, Production, Archived) and approvals/governance for promotion.\n",
      "- MLflow Tracking: records/logs ML experiments; captures parameters, metrics, artifacts, and metadata; enables comparing runs and reproducibility; accessible via API and viewable in a web UI.\n",
      "\n",
      "Be concise, avoid speculation, and do not introduce unsupported terminology. Output only the answer (no preamble, no citations unless requested).\n",
      "Iteration 6: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 7: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 7: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY the information supported by the provided reference document/context for this task.\n",
      "\n",
      "Requirements:\n",
      "- Do not add extra facts, features, or terminology that are not explicitly stated in the reference (e.g., donâ€™t mention â€œaliases,â€ â€œtransfer learning,â€ â€œfine-tuning,â€ or similar items unless the reference says so).\n",
      "- If the question asks for a specific format (e.g., â€œdefinition + 2 best practices,â€ â€œone paragraph of 3â€“4 sentences,â€ â€œnumber the top 3 benefitsâ€), follow it exactly.\n",
      "- Prefer wording that closely matches the reference. Avoid embellishments such as extra qualifiers (e.g., â€œlength and styleâ€) unless the reference includes them.\n",
      "- If the reference does not contain enough information to fully answer, say what is missing and answer only the parts that are supported.\n",
      "\n",
      "Task-specific content cues (use only when supported by the reference):\n",
      "- Prompt engineering: define as designing/structuring/refining prompts/inputs to guide an AI model toward accurate, relevant, reliable outputs; best practices may include being specific/providing context (including desired format) and iterating/testing systematically (examples/edge cases can be part of iteration if stated).\n",
      "- MLflow Model Registry: describe as a centralized repository/store for managing the model lifecycle with model versioning and metadata/lineage; may include registering from runs, tracking versions, attaching descriptions/tags/artifacts, and stage-based workflows such as Staging/Production/Archived, plus collaboration/access control/review-approve if explicitly mentioned.\n",
      "- Vector embeddings: benefits may include capturing semantic meaning for semantic search/retrieval, providing dense informative features for tasks (classification/clustering/recommendation/similarity), and enabling efficient nearest-neighbor similarity search and clustering at scaleâ€”only if these appear in the reference.\n",
      "\n",
      "Output:\n",
      "- Provide just the answer in the required format. No preamble, no citations unless asked.\n",
      "Iteration 7: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 8: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 8: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using only information that is explicitly supported by the provided reference/document/context for this task (do not add plausible-sounding details or common â€œextraâ€ facts that are not stated).\n",
      "\n",
      "Requirements:\n",
      "- Follow all formatting constraints in the question exactly (e.g., â€œexactly N sentencesâ€, required section headers, required number of bullet points, etc.).\n",
      "- Be accurate and concise; include only claims that can be directly grounded in the source.\n",
      "- If the question asks for a comparison, cover both sides and contrast them only with supported differences (e.g., RAG retrieves external documents at inference/query time and keeps the base model unchanged; fine-tuning updates the modelâ€™s weights using training data and is harder to update).\n",
      "- Do NOT introduce unsupported specifics such as â€œautomatic loggingâ€, â€œUI dashboardâ€, â€œloss of general capabilitiesâ€, or any other detail not present in the source.\n",
      "- If the source does not contain enough information to answer a part of the question without guessing, say so briefly (within the given formatting constraints) rather than inventing details.\n",
      "Iteration 8: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 9: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 9: All subsample scores perfect. Skipping.\n",
      "Iteration 9: Reflective mutation did not propose a new candidate\n",
      "Iteration 10: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 10: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly supported by the provided reference document/context (if any).\n",
      "\n",
      "Rules:\n",
      "- Do not add extra facts, mechanisms, features, or examples that are not clearly stated in the source.\n",
      "- If the question asks for â€œtop N,â€ â€œbenefits,â€ â€œcompare,â€ etc., select and rephrase ONLY items that the source supports; do not introduce common-knowledge additions (e.g., â€œtransfer learning,â€ â€œaliases,â€ â€œlosing general capabilitiesâ€) unless the source explicitly mentions them.\n",
      "- Keep any required formatting constraints exactly (e.g., â€œnumber each benefit,â€ â€œexactly 2 sentences,â€ â€œone paragraph of 3â€“4 sentencesâ€).\n",
      "- Prefer tight paraphrase over embellishment. Avoid parenthetical expansions unless directly grounded in the source.\n",
      "- If the source does not contain enough information to answer fully, say what is missing and answer only the supported parts (or request the needed context).\n",
      "\n",
      "Now answer: {{ question }}\n",
      "Iteration 10: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 11: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 11: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly present in the provided source material (the â€œdocumentâ€/context for the task). Do not add extra facts, common knowledge, or plausible-sounding benefits/best practices that are not directly supported.\n",
      "\n",
      "Requirements:\n",
      "- Follow the formatting constraints stated in the question exactly (e.g., â€œDefinition, then Use Cases (2 bullet points)â€, â€œNumber each benefitâ€, â€œdefinition followed by 2 best practicesâ€).\n",
      "- Keep the content tightly aligned to what the source material states. If the question asks for N items, provide exactly N items, each clearly supported by the source.\n",
      "- Paraphrase is allowed, but do not introduce new claims (e.g., donâ€™t mention â€œtransfer learningâ€ or â€œcompression of sparse high-dimensional dataâ€ unless the source explicitly mentions them).\n",
      "- If the question requests best practices, list only those that the source enumerates; do not swap in alternatives (e.g., if the source says â€œIterate and test,â€ donâ€™t replace it with â€œProvide examplesâ€ unless the source treats it as a standalone best practice).\n",
      "- If the source does not contain enough information to fully answer as requested, say what is missing and provide only the supported portions without guessing.\n",
      "Iteration 11: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 12: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 12: Proposed new text for gepa-qa-simple: Answer the userâ€™s question directly and concisely, strictly adhering to any formatting constraints the question specifies (e.g., â€œexactly N sentencesâ€, â€œone paragraphâ€, etc.).\n",
      "\n",
      "Factuality requirements:\n",
      "- Only state claims you are confident are true and that are supported by the information available in the prompt; do not add extra â€œnice-to-haveâ€ details that are not explicitly warranted.\n",
      "- Avoid inserting niche product features unless you are sure they exist. In particular:\n",
      "  - Do NOT claim MLflow Model Registry uses â€œaliasesâ€ to transition models through stages unless the prompt explicitly provides that.\n",
      "  - Do NOT claim MLflow Tracking â€œautomatically logsâ€ experiments unless the prompt explicitly provides that.\n",
      "  - Do NOT claim fine-tuning â€œmay lose general capabilitiesâ€ unless the prompt explicitly provides that.\n",
      "- Prefer grounded, widely accepted descriptions: e.g., MLflow Model Registry as centralized model lifecycle management with versioning, metadata/lineage, stage transitions (e.g., Staging/Production), and annotations; MLflow Tracking as recording/organizing experiments with parameters, metrics, and artifacts and viewing/searching via UI or API; RAG as retrieving documents at inference/query time while keeping base model fixed vs fine-tuning changing model weights using training data.\n",
      "\n",
      "Style:\n",
      "- Be clear and beginner-friendly when requested.\n",
      "- Do not mention â€œthe documentâ€ or â€œsourcesâ€; just answer.\n",
      "- If a constraint is given (sentence count/paragraph count), comply exactly.\n",
      "Iteration 12: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 13: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 13: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly supported by the provided reference document/context for this task.\n",
      "\n",
      "Requirements:\n",
      "- Follow the userâ€™s formatting constraints exactly (e.g., â€œexactly 2 sentencesâ€, â€œone paragraph of 3â€“4 sentencesâ€, â€œnumber each benefitâ€).\n",
      "- Be faithful to the reference: do NOT add plausible but unstated details, examples, features, or mechanisms (e.g., donâ€™t mention â€œaliasesâ€, â€œannotationsâ€, â€œloss of general capabilitiesâ€, â€œsparseâ†’dense compressionâ€, or â€œtransfer learningâ€ unless the reference explicitly says so).\n",
      "- If the question asks for something not fully supported by the reference, either:\n",
      "  - answer only the supported parts and explicitly state what is not specified in the reference, or\n",
      "  - ask a brief clarifying question about the missing information.\n",
      "- Keep the answer concise and directly responsive; avoid extra commentary beyond whatâ€™s asked.\n",
      "Iteration 13: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 14: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 14: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly supported by the provided reference/document for that question (i.e., do not rely on outside knowledge). \n",
      "\n",
      "Requirements:\n",
      "- Follow any formatting constraints in the question exactly (e.g., â€œexactly 3 sentencesâ€, â€œDefinition then 2 bullet pointsâ€, etc.).\n",
      "- Do not introduce extra claims, features, or phrasing that are not stated in the reference. Avoid common-but-unstated additions such as:\n",
      "  - â€œprovide examplesâ€ as a separate best practice unless the reference lists it as such (it may only be mentioned as optional within another point),\n",
      "  - â€œautomatically logsâ€ for MLflow Tracking unless explicitly stated,\n",
      "  - â€œmodel artifactsâ€ unless explicitly stated,\n",
      "  - calling the UI an â€œMLflow UI dashboardâ€ unless explicitly stated.\n",
      "- If the question requests N items (e.g., 2 best practices / 2 use cases), provide exactly N, and ensure each item is directly supported.\n",
      "- Prefer concise paraphrases that preserve the reference meaning; when unsure whether something is supported, omit it or qualify it strictly to what is stated.\n",
      "\n",
      "Output only the answer (no meta commentary about the reference or your process).\n",
      "Iteration 14: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 15: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 15: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY information that is explicitly stated in the provided source/document for this task (the evaluator will check every claim for support).\n",
      "\n",
      "Rules:\n",
      "- Do not add extra details, features, or implications that are not clearly supported by the source, even if they are commonly true (e.g., donâ€™t mention MLflow â€œaliasesâ€ or â€œannotationsâ€ unless the source says so; donâ€™t claim fine-tuning â€œmay lose general capabilitiesâ€ unless stated; donâ€™t add â€œprovide examplesâ€ as a separate best practice unless the source presents it as such).\n",
      "- If the question asks for a specific format, follow it exactly:\n",
      "  - If it asks for â€œa definition followed by 2 best practices,â€ give exactly that.\n",
      "  - If it asks for â€œone paragraph of 3â€“4 sentences,â€ output a single paragraph with 3â€“4 sentences total.\n",
      "  - If it asks for â€œexactly 2 sentences,â€ output exactly 2 sentences.\n",
      "- Prefer the sourceâ€™s wording and scope. Keep statements minimal and directly supported.\n",
      "- If required information is missing from the source, say so briefly rather than guessing or filling in with outside knowledge.\n",
      "\n",
      "Now answer: {{ question }}\n",
      "Iteration 15: New subsample score 0.0 is not better than old score 0.0, skipping\n",
      "Iteration 16: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 16: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using ONLY the information that is explicitly supported by the provided reference document/context for the task.\n",
      "\n",
      "Requirements:\n",
      "- Do not add outside knowledge, common facts, or plausible â€œextraâ€ details that are not stated in the document.\n",
      "- If the question asks for N items (e.g., â€œtop 3â€), provide exactly N items, but each item must be directly supported by the document. If the document doesnâ€™t support enough items, state that the document only supports K items and list only those K.\n",
      "- Preserve any formatting constraints in the question exactly (e.g., â€œexactly 3 sentencesâ€, â€œNumber each benefitâ€, â€œDefinition then Use Cases (2 bullet points)â€).\n",
      "- Be precise about wording. Avoid inserting claims like â€œautomaticâ€, â€œUI dashboardâ€, â€œtransfer learningâ€, â€œfine-tuningâ€, â€œcompression of high-dimensional sparse dataâ€, or â€œfaster computationâ€ unless the document explicitly mentions them.\n",
      "- Prefer brief, extractive phrasing that mirrors the documentâ€™s statements. If needed, you may paraphrase, but do not introduce new concepts or examples not found in the document.\n",
      "- If the document does not contain enough information to answer the question as asked, say so plainly and answer only what the document supports.\n",
      "Iteration 16: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "Iteration 17: Selected program 0 score: 0.3333333333333333\n",
      "Iteration 17: Proposed new text for gepa-qa-simple: Answer the userâ€™s question using only information that is explicitly stated or clearly implied by the provided source/document for this task.\n",
      "\n",
      "Requirements:\n",
      "- Follow any formatting constraints in the question exactly (e.g., â€œexactly 2 sentencesâ€, â€œnumber each benefitâ€, â€œDefinition then Use Cases (2 bullet points)â€).\n",
      "- Be concise and directly responsive; do not add extra sections or commentary beyond what the question requests.\n",
      "- Do NOT introduce facts, claims, examples, or tradeoffs that are not supported by the source/document. Avoid â€œcommon knowledgeâ€ additions (e.g., â€œfine-tuning may reduce general capabilitiesâ€, â€œembeddings compress sparse vectorsâ€, â€œtransfer learningâ€) unless the source explicitly mentions them.\n",
      "- If the question asks for N items, provide exactly N.\n",
      "- Prefer safe, source-grounded phrasing (e.g., â€œRAG retrieves relevant external documents at query/inference time to augment contextâ€ and â€œfine-tuning updates model weights using training dataâ€ only if supported).\n",
      "- If the source does not contain enough information to fully answer all required parts, say what is missing and answer only the parts that are supported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:43:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for prompt version to finish creation. Prompt name: gepa-qa-simple, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17: New subsample score 0.0 is not better than old score 1.0, skipping\n",
      "ğŸƒ View run unleashed-trout-623 at: http://localhost:5000/#/experiments/1/runs/bf28b219f44443e998c6ccd88197d48e\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n",
      "\n",
      "âœ… GEPA optimization complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-2e743fb0681b38beb21b07c79b1363ab&amp;experiment_id=1&amp;trace_id=tr-3f74f64dea3f9a6116b2acf584fc38b7&amp;experiment_id=1&amp;trace_id=tr-1281feb02a4280214b53e4c78304789b&amp;experiment_id=1&amp;trace_id=tr-6d4cf26280967fb25eb9c25d4b9e5e9e&amp;experiment_id=1&amp;trace_id=tr-21e749968bb7cf56a80d5d42a74de86d&amp;experiment_id=1&amp;trace_id=tr-9b9b33a8deeb08e97e514b976ec8309e&amp;experiment_id=1&amp;trace_id=tr-8a7dc2973914e6772fb32c59cef70983&amp;experiment_id=1&amp;trace_id=tr-48b197bda70063eeb76f6dd589ea99ac&amp;experiment_id=1&amp;trace_id=tr-8b8f48e5fbd8ff0983ee394508a2cb96&amp;experiment_id=1&amp;trace_id=tr-baee490042e6b64c9dbe316dc20001c7&amp;experiment_id=1&amp;version=3.9.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-2e743fb0681b38beb21b07c79b1363ab), Trace(trace_id=tr-3f74f64dea3f9a6116b2acf584fc38b7), Trace(trace_id=tr-1281feb02a4280214b53e4c78304789b), Trace(trace_id=tr-6d4cf26280967fb25eb9c25d4b9e5e9e), Trace(trace_id=tr-21e749968bb7cf56a80d5d42a74de86d), Trace(trace_id=tr-9b9b33a8deeb08e97e514b976ec8309e), Trace(trace_id=tr-8a7dc2973914e6772fb32c59cef70983), Trace(trace_id=tr-48b197bda70063eeb76f6dd589ea99ac), Trace(trace_id=tr-8b8f48e5fbd8ff0983ee394508a2cb96), Trace(trace_id=tr-baee490042e6b64c9dbe316dc20001c7)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "from ipykernel.iostream import OutStream\n",
    "\n",
    "# === Fix for GEPA Unicode surrogate characters ===\n",
    "# GEPA's internal output contains Unicode surrogates that crash Jupyter's\n",
    "# ZMQ/tornado JSON encoder. We fix at two levels:\n",
    "#\n",
    "# Level 1: Patch OutStream.write at the CLASS level to sanitize all output.\n",
    "# This ensures surrogates are stripped before they reach ipykernel's buffer,\n",
    "# regardless of how write() is called (instance, class, or thread).\n",
    "_orig_outstream_write = OutStream.write\n",
    "\n",
    "def _safe_outstream_write(self, string):\n",
    "    if isinstance(string, str):\n",
    "        string = string.encode(\"utf-8\", errors=\"replace\").decode(\"utf-8\")\n",
    "    return _orig_outstream_write(self, string)\n",
    "\n",
    "OutStream.write = _safe_outstream_write\n",
    "\n",
    "# Level 2: Suppress tornado/ZMQ error log messages for any surrogates\n",
    "# that reach non-stdout kernel messages (these errors are non-fatal noise).\n",
    "for _logger_name in (\"tornado.general\", \"tornado.application\"):\n",
    "    logging.getLogger(_logger_name).setLevel(logging.CRITICAL)\n",
    "\n",
    "# Run GEPA prompt optimization\n",
    "print(\"\\ud83d\\udd04 Running GEPA prompt optimization...\\n\")\n",
    "print(\"   This will iterate through evaluate \\u2192 reflect \\u2192 mutate \\u2192 select cycles.\")\n",
    "print(\"   Budget: 100 metric calls (may take 3-5 minutes)\\n\")\n",
    "\n",
    "result = optimize_prompts(\n",
    "    predict_fn=predict_qa,\n",
    "    train_data=train_data,\n",
    "    prompt_uris=[baseline_prompt.uri],\n",
    "    optimizer=GepaPromptOptimizer(\n",
    "        reflection_model=optimizer_model,\n",
    "        max_metric_calls=100,\n",
    "        display_progress_bar=False,\n",
    "    ),\n",
    "    scorers=[Correctness(model=optimizer_model)],\n",
    ")\n",
    "\n",
    "print(\"\\n\\u2705 GEPA optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Compare Original vs. Optimized Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback BaseAsyncIOLoop._handle_events(43, 1)\n",
      "handle: <Handle BaseAsyncIOLoop._handle_events(43, 1)>\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 71-72: surrogates not allowed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 143, in orjson_packer\n",
      "    return orjson.dumps(obj, default=json_default, option=option)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: str is not valid UTF-8: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 100-101: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jules/.local/share/uv/python/cpython-3.11.13-macos-aarch64-none/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 208, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/zmq/eventloop/zmqstream.py\", line 600, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/zmq/eventloop/zmqstream.py\", line 629, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/zmq/eventloop/zmqstream.py\", line 550, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/ipykernel/iostream.py\", line 171, in _handle_event\n",
      "    event_f()\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/ipykernel/iostream.py\", line 644, in _flush\n",
      "    self.session.send(\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 856, in send\n",
      "    to_send = self.serialize(msg, ident)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 727, in serialize\n",
      "    content = self.pack(content)\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 145, in orjson_packer\n",
      "    return json_packer(obj)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jules/git-repos/mlflow-misc/.venv/lib/python3.11/site-packages/jupyter_client/session.py\", line 111, in json_packer\n",
      "    ).encode(\"utf8\", errors=\"surrogateescape\")\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 100-101: surrogates not allowed\n"
     ]
    }
   ],
   "source": [
    "def _safe(s):\n",
    "    \"\"\"Strip Unicode surrogates for safe display in Jupyter.\"\"\"\n",
    "    if isinstance(s, str):\n",
    "        return s.encode(\"utf-8\", errors=\"replace\").decode(\"utf-8\")\n",
    "    return str(s)\n",
    "\n",
    "# Display before/after comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"\\ud83d\\udcca GEPA Optimization Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\\ud83d\\udcc8 Score Improvement:\")\n",
    "if result.initial_eval_score is not None:\n",
    "    print(f\"   Initial score: {result.initial_eval_score:.3f}\")\n",
    "else:\n",
    "    print(\"   Initial score: N/A\")\n",
    "if result.final_eval_score is not None:\n",
    "    print(f\"   Final score:   {result.final_eval_score:.3f}\")\n",
    "else:\n",
    "    print(\"   Final score:   N/A\")\n",
    "if result.initial_eval_score is not None and result.final_eval_score is not None:\n",
    "    improvement = result.final_eval_score - result.initial_eval_score\n",
    "    print(f\"   Improvement:   {improvement:+.3f}\")\n",
    "\n",
    "# Load the optimized prompt directly from the registry to ensure we\n",
    "# see the actual registered version (not just the in-memory object)\n",
    "optimized = result.optimized_prompts[0]\n",
    "registry_prompt = mlflow.genai.load_prompt(f\"prompts:/{optimized.name}/{optimized.version}\")\n",
    "\n",
    "print(f\"\\n\\ud83d\\udcdd Original Prompt (version {baseline_prompt.version}):\")\n",
    "print(f\"   '{baseline_prompt.template}'\")\n",
    "\n",
    "print(f\"\\n\\ud83d\\ude80 Optimized Prompt (version {optimized.version}):\")\n",
    "print(f\"   '{_safe(registry_prompt.template)}'\")\n",
    "\n",
    "if baseline_prompt.template.strip() == _safe(registry_prompt.template).strip():\n",
    "    print(\"\\n\\u26a0\\ufe0f  Note: The optimized template is identical to the baseline.\")\n",
    "    print(\"   This can happen when the baseline already scores well on the\")\n",
    "    print(\"   training data. Try adding harder examples or increasing the budget.\")\n",
    "\n",
    "print(\"\\n\\ud83d\\udd17 The optimized prompt has been automatically registered\")\n",
    "print(f\"   as version {optimized.version} in the Prompt Registry!\")\n",
    "print(f\"   View it in MLflow UI \\u2192 Prompt Registry \\u2192 {_safe(optimized.name)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\n\\ud83d\\udca1 Key Takeaway:\")\n",
    "print(\"   GEPA automatically learned to add structure, instructions,\")\n",
    "print(\"   and constraints that we would normally write by hand.\")\n",
    "print(\"   Combined with the Prompt Registry, optimized prompts are\")\n",
    "print(\"   versioned and ready for deployment via aliases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. How **GEPA** automatically optimizes prompts through evaluate-reflect-mutate cycles\n",
    "2. Using `mlflow.genai.optimize_prompts()` with the **Prompt Registry**\n",
    "3. Preparing **training data** and a **predict function** for optimization\n",
    "4. Comparing **before/after** prompt quality with the `Correctness` scorer\n",
    "5. Optimized prompts are **automatically versioned** in the registry\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Automate what you can**: GEPA systematically improves prompts that would take many manual iterations\n",
    "- **Data-driven optimization**: Training examples define what \"good\" looks like for the algorithm\n",
    "- **Registry integration**: Optimized prompts flow directly into the Prompt Registry for versioning and deployment\n",
    "- **Combine approaches**: Use GEPA for initial optimization, then fine-tune manually if needed\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**\\ud83d\\udcd3 Notebook 1.9: Complete RAG Application**\n",
    "\n",
    "Learn how to:\n",
    "- Build a full RAG pipeline with end-to-end tracing\n",
    "- Evaluate RAG quality with RAGAS metrics\n",
    "- Track performance, cost, and retrieval quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
